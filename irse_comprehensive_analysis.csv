Paper_ID,Title,Authors,Primary_Models,Data_Preprocessing,Training_Approach,LLM_Integration,Best_Performance,Key_Findings,Innovation_Level
T7-1,Generative AI for Software Metadata: Overview of IRSE Track,"Majumdar, S. et al.","Neural Networks, SVM, Random Forest","Standard text preprocessing, TF-IDF vectorization, feature extraction","Cross-validation, hyperparameter tuning, SMOTE balancing",Comparative analysis of human vs LLM generated labels,"F1: 0.885 (Neural Network), Precision: 0.90, Recall: 0.87",LLM labels reduce overfitting but introduce bias; 1.5-4% F1-score improvements,High - Track overview with comprehensive methodology analysis
T7-2,A ML-LLM pairing for better code comment classification,"Abi Akl, H.","Neural Network, Random Forest, Voting Classifier","SMOTE balancing, sentence embeddings using CodeSearchNet model","Repeated Stratified K-Fold (10 folds, 3 repetitions), SMOTE balancing",ChatGPT data generation (421 samples),"Macro-F1: 0.884 (Neural Network), 1.5% improvement with LLM data",Neural Networks outperform classical ML; LLM augmentation provides modest gains,Medium - Novel ML-LLM pairing approach with systematic evaluation
T7-3,Software Metadata Classification based on Generative AI,"Killivalavan, S., Thenmozhi, D.","SVM, ANN with multiple activation functions","BERT embeddings, Curie Model preprocessing","Grid search optimization, L2 regularization, cross-entropy loss",OpenAI Curie Model + BERT for label generation (1239 samples),"SVM: 85% precision (6% increase), ANN: 74.6% recall (1.5% increase)",6% precision increase with SVM; generative AI effective for metadata classification,Medium - Integration of multiple AI models for metadata classification
T7-4,Leveraging Generative AI: Improving Software Metadata Classification,"Syed, S., Deborah, A.","BERT, Logistic Regression, Decision Tree, KNN, SVM, Gradient Boosting, Random Forest","Text normalization, tokenization, outlier removal using Z-scores","5-fold cross-validation, hyperparameter tuning with random search",BERT for synthetic data labeling (739 samples),"F1: 0.815 (Random Forest), Precision: 0.795, Recall: 0.837",Random Forest achieves best performance; LLM augmentation shows improvements,Medium - BERT-based augmentation with comprehensive model comparison
T7-5,Source Code Comment Classification using machine learning algorithms,"Datta, T.","Logistic Regression, SVM, Multinomial Naive Bayes","Lemmatization, tokenization, TF-IDF vectorization","90-10 train-test split, cross-entropy and hinge loss functions",ChatGPT-4 for labeling (334 samples),"Accuracy: 84.72% (SVM), 83.42% (Logistic Regression), 50.45% (Naive Bayes)",SVM consistently outperforms other algorithms; LLM data introduces some noise,Low - Standard ML approaches with basic LLM augmentation
T7-6,Enhancing Binary Code Comment Quality Classification,"Arumugam, R., Deborah, A.","BERT, Decision Tree, ANN, SVM, Random Forest, Gradient Boosting, Logistic Regression","GitHub API extraction, manual labeling, BERT tokenization","80-20 train-test split, cross-entropy loss with BERT fine-tuning",BERT for synthetic comment generation and labeling,"F1: 0.885 (Decision Tree), 0.884 (ANN) with augmented data",Decision Tree and ANN show best performance with augmented data,Medium - Comprehensive model comparison with generative AI integration
T7-7,Binary Classification of Source Code Comments using Machine Learning,"Sarkar, L.","Logistic Regression, SVM, Multinomial Naive Bayes","Lemmatization, tokenization, TF-IDF vectorization","90-10 train-test split, 5-fold cross-validation",ChatGPT-4 for data augmentation (332 samples),"Accuracy: 84.12% (SVM), 83.32% (Logistic Regression) with augmented data",Models show slight decrease with LLM data due to noise introduction,Low - Traditional ML methods with minimal innovation
T7-8,A study of the impact of generative AI-based data augmentation,"Kumari, T., Charan, C.S., Das, A.","SVM with RBF kernel, ELMo embeddings","ELMo contextual embeddings, 200-dimensional representations","80-20 split, RBF kernel SVM training with ELMo representations",ChatGPT for usefulness label generation (510 samples),"Accuracy: 92.76% (Dataset2), F1: 0.94 (Useful class)",Original data performs best (92.76%); extra-generated data shows lower accuracy,Medium - Systematic study of LLM impact with multiple dataset combinations
T7-9,Leveraging Language Models for Code Comment Classification,"Patel, J.","GPT-3, DistilGPT, GPT-2, Codex, StarCoder","Zero-shot/few-shot prompting, synthetic data generation","Zero-shot, few-shot (10 examples), instruction fine-tuning approaches",ChatGPT synthetic comment generation for training data,"Accuracy: 96% (GPT-3), 94% (Codex), 89% (GPT-2)",LLMs achieve near human-level performance (96%); contextual mastery crucial,High - Comprehensive LLM evaluation with human-level performance analysis
T7-10,Enhancing Code Comment Classification Using Language Models,"Barot, J.","GPT-3, CodeLlama, StarCoder, Llama-2-Coder","Zero-shot/few-shot prompting, instruction fine-tuning","Zero-shot, few-shot, instruction fine-tuning with QLoRA and PEFT",ChatGPT data generation for augmentation,"Accuracy: 96% (GPT-3), 94% (Codex), 93% (Derby dataset)",Code LLMs outperform generic LLMs; zero-shot better than few-shot for dissimilar data,High - Extensive LLM comparison with multiple training approaches
T7-11,Assessing the Utility of C Comments with SVM and Na√Øve Bayes,"Mitra, A.","SVM (linear kernel), Naive Bayes Classifier","Text preprocessing, TfidfVectorizer, POS tagging, lemmatization","70-30 train-validation split, TF-IDF feature extraction",GPT-3 for dataset augmentation and labeling,"F1: 0.783 (SVM), 0.695 (Naive Bayes) with augmentation",SVM provides reasonable baseline; GPT-3 augmentation shows minimal improvement,Low - Basic ML models with limited LLM integration
T7-12,Source Code Comment Classification using Naive Bayes and SVM,"Shah, R.J.","Multinomial Naive Bayes, SVM (hinge loss)","Structural feature extraction, comment length, position analysis","Hinge loss for SVM, probabilistic training for Naive Bayes",ChatGPT-3.5-turbo for additional 500 samples,"F1: 0.776 (SVM), 0.640 (Naive Bayes) with ChatGPT augmentation",Structural features sufficient for classification; augmentation provides minor gains,Low - Traditional feature-based approach with minimal augmentation
T7-13,On the Impact of Synthetic Data on Code Comment Usefulness Prediction,"Agarwal, V.","Random Forest, Universal Sentence Encoder","Universal Sentence Encoder embeddings, bootstrap sampling","80-20 split, out-of-bag error estimation, bootstrap aggregation",GPT-3.5-turbo for synthetic data generation (233 samples),"F1: 0.795 (Random Forest), consistent performance with/without augmentation",Synthetic data practically indistinguishable from original; consistent performance,Medium - Focused study on synthetic data impact with Random Forest
T7-14,Exploring LLM-based Data Augmentation Techniques,"Dalmia, P.","Logistic Regression, Universal Sentence Encoder",Universal Sentence Encoder embeddings,"80-20 split, cross-entropy loss with threshold 0.6",GPT-3.5-turbo for data augmentation (233 samples),"F1: 0.80 (Logistic Regression), consistent with/without augmentation",GPT-generated data maintains classification quality; augmentation effectiveness validated,Medium - Practical application of LLM augmentation with clear methodology
T7-15,Exploring Large Language Models for Code Explanation,"Bhattacharya, P. et al.","Llama-2, CodeLlama, CodeUp, StarCoder, Llama-2-Coder","Zero-shot/few-shot prompting, BLEU evaluation","Zero-shot with prompt engineering, few-shot with conala-train examples",Code explanation generation using multiple LLMs,"BLEU-1: 0.189, CodeBERT: 0.498 (CodeLlama-13B-Instruct)",Code LLMs superior to generic models; zero-shot effective for dissimilar distributions,High - Multi-LLM evaluation for code explanation with comprehensive analysis
